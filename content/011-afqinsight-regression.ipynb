{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Predict age from white matter features\n",
    "\n",
    "Predict subject age from white matter features. This example fetches the\n",
    "Weston-Havens dataset described in Yeatman et al [1]_. This dataset contains\n",
    "tractometry features from 77 subjects ages 6-50. The plots display the absolute\n",
    "value of the mean regression coefficients (averaged across cross-validation\n",
    "splits) for the mean diffusivity (MD) features.\n",
    "\n",
    "Predictive performance for this example is quite poor. In a research setting,\n",
    "one might have to ensemble a number of SGL estimators together and conduct a\n",
    "more thorough search of the hyperparameter space. For more details, please see\n",
    "[2]_.\n",
    "\n",
    ".. [1]  Jason D. Yeatman, Brian A. Wandell, & Aviv A. Mezer, \"Lifespan\n",
    "    maturation and degeneration of human brain white matter\" Nature\n",
    "    Communications, vol. 5:1, pp. 4932, 2014 DOI: 10.1038/ncomms5932\n",
    "\n",
    ".. [2]  Adam Richie-Halford, Jason Yeatman, Noah Simon, and Ariel Rokem\n",
    "   \"Multidimensional analysis and detection of informative features in human\n",
    "   brain white matter\" PLOS Computational Biology, 2021 DOI:\n",
    "   10.1371/journal.pcbi.1009136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from groupyr.decomposition import GroupPCA\n",
    "\n",
    "from afqinsight.neurocombat_sklearn import CombatModel\n",
    "from afqinsight.plot import plot_tract_profiles\n",
    "from afqinsight import make_afq_regressor_pipeline\n",
    "from afqinsight import AFQDataset, load_afq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch example data\n",
    "\n",
    "The :func:`download_weston_havens` function download the data used in this\n",
    "example and places it in the `~/.cache/afq-insight/weston_havens` directory.\n",
    "If the directory does not exist, it is created. The data follows the format\n",
    "expected by the :func:`load_afq_data` function: a file called `nodes.csv` that\n",
    "contains AFQ tract profiles and a file called `subjects.csv` that contains\n",
    "information about the subjects. The two files are linked through the\n",
    "`subjectID` column that should exist in both of them. For more information\n",
    "about this format, see also the [AFQ-Browser documentation](https://yeatmanlab.github.io/AFQ-Browser/dataformat.html) (items 2 and 3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "afqdata = AFQDataset.from_files(\n",
    "    fn_nodes=\"/data/afq-insight/hbn/nodes.csv\",\n",
    "    fn_subjects=\"/data/afq-insight/hbn/subjects.tsv\",\n",
    "    dwi_metrics=[\"dki_md\", \"dki_fa\"],\n",
    "    target_cols=[\"age\", \"sex\", \"scan_site_id\"],\n",
    "    label_encode_cols = [\"sex\", \"scan_site_id\"],\n",
    "    index_col=\"subject_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afqdata.drop_target_na()\n",
    "print(afqdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================\n",
    "Harmonize HBN data using ComBat\n",
    "===============================\n",
    "\n",
    "This example loads AFQ data from the Healthy Brain Network (HBN) preprocessed\n",
    "diffusion derivatives [1]_. The HBN is a landmark pediatric mental health study.\n",
    "Over the course of the study, it will collect diffusion MRI data from\n",
    "approximately 5,000 children and adolescents. We recently processed the\n",
    "available data from over 2,000 of these subjects, and provide the tract profiles\n",
    "from this dataset, which can be downloaded from AWS thanks to\n",
    "[INDI](http://fcon_1000.projects.nitrc.org/).\n",
    "\n",
    "We first load the data by using the :func:`AFQDataset.from_files` static method\n",
    "and supplying AWS S3 URIs instead of local file names. We then impute missing\n",
    "values and plot the mean bundle profiles by scanning site, noting that there are\n",
    "substantial site differences. Lastly, we harmonize the site differences using\n",
    "NeuroComBat [2]_ and plot the harmonized bundle profiles to verify that the site\n",
    "differences have been removed.\n",
    "\n",
    ".. [1]  Adam Richie-Halford, Matthew Cieslak, Lei Ai, Sendy Caffarra, Sydney\n",
    "   Covitz, Alexandre R. Franco, Iliana I. Karipidis, John Kruper, Michael\n",
    "   Milham, BÃ¡rbara Avelar-Pereira, Ethan Roy, Valerie J. Sydnor, Jason Yeatman,\n",
    "   The Fibr Community Science Consortium, Theodore D. Satterthwaite, and Ariel\n",
    "   Rokem,\n",
    "   \"An open, analysis-ready, and quality controlled resource for pediatric brain\n",
    "   white-matter research\"\n",
    "   bioRxiv 2022.02.24.481303;\n",
    "   doi: https://doi.org/10.1101/2022.02.24.481303\n",
    "\n",
    ".. [2] Jean-Philippe Fortin, Drew Parker, Birkan Tunc, Takanori Watanabe, Mark A\n",
    "   Elliott, Kosha Ruparel, David R Roalf, Theodore D Satterthwaite, Ruben C Gur,\n",
    "   Raquel E Gur, Robert T Schultz, Ragini Verma, Russell T Shinohara.\n",
    "   \"Harmonization Of Multi-Site Diffusion Tensor Imaging Data\"\n",
    "   NeuroImage, 161, 149-170, 2017;\n",
    "   doi: https://doi.org/10.1016/j.neuroimage.2017.08.047\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#############################################################################\n",
    "# Train / test split\n",
    "# ------------------\n",
    "#\n",
    "# We can pass the :class:`AFQDataset` class instance to scikit-learn's\n",
    "# :func:`train_test_split` function, just as we would with an array.\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(afqdata, test_size=0.25)\n",
    "\n",
    "##########################################################################\n",
    "# Impute missing values\n",
    "# ---------------------\n",
    "#\n",
    "# Next we impute missing values using median imputation. We fit the imputer\n",
    "# using the training set and then use it to transform both the training and test\n",
    "# sets.\n",
    "\n",
    "imputer = dataset_train.model_fit(SimpleImputer(strategy=\"median\"))\n",
    "dataset_train = dataset_train.model_transform(imputer)\n",
    "dataset_test = dataset_test.model_transform(imputer)\n",
    "\n",
    "##########################################################################\n",
    "# Harmonize the sites and replot\n",
    "# ------------------------------\n",
    "#\n",
    "# We can see that there are substantial scan site differences in both the\n",
    "# FA and MD profiles. Let's use neuroComBat to harmonize the site differences\n",
    "# and then replot the mean bundle profiles.\n",
    "#\n",
    "\n",
    "# N.B. We use the excellent `neurocombat_sklearn\n",
    "# <https://github.com/Warvito/neurocombat_sklearn>`_ package, which we have\n",
    "# ported and updated to support recent versions of scikit learn,\n",
    "# to apply ComBat to\n",
    "# our data. We love this library, however, it is not fully compliant with the\n",
    "# scikit-learn transformer API, so we cannot use the\n",
    "# :func:`AFQDataset.model_fit_transform` method to apply this transformer to our\n",
    "# dataset. No problem! We can simply copy the unharmonized dataset into a new\n",
    "# variable and then overwrite the features of the new dataset with the ComBat\n",
    "# output.\n",
    "#\n",
    "# Lastly, we replot the mean bundle profiles and confirm that ComBat did its\n",
    "# job.\n",
    "\n",
    "# Fit the ComBat transformer to the training set\n",
    "\n",
    "combat = CombatModel()\n",
    "combat.fit(\n",
    "    dataset_train.X,\n",
    "    dataset_train.y[:, 2][:, np.newaxis],\n",
    "    dataset_train.y[:, 1][:, np.newaxis],\n",
    "    dataset_train.y[:, 0][:, np.newaxis],\n",
    ")\n",
    "\n",
    "\n",
    "# And then transform a copy of the test set and a copy of the train set:\n",
    "harmonized_test = dataset_test.copy()\n",
    "harmonized_test.X = combat.transform(\n",
    "    dataset_test.X,\n",
    "    dataset_test.y[:, 2][:, np.newaxis],\n",
    "    dataset_test.y[:, 1][:, np.newaxis],\n",
    "    dataset_test.y[:, 0][:, np.newaxis],\n",
    ")\n",
    "\n",
    "harmonized_train = dataset_train.copy()\n",
    "harmonized_train.X = combat.transform(\n",
    "    dataset_train.X,\n",
    "    dataset_train.y[:, 2][:, np.newaxis],\n",
    "    dataset_train.y[:, 1][:, np.newaxis],\n",
    "    dataset_train.y[:, 0][:, np.newaxis],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an analysis pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "do_group_pca = True\n",
    "\n",
    "if do_group_pca:\n",
    "    n_components = 10\n",
    "\n",
    "    # The next three lines retrieve the group structure of the group-wise PCA\n",
    "    # and store it in ``groups_pca``. We do not use the GroupPCA transformer\n",
    "    # for anything else\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    gpca = GroupPCA(n_components=n_components, groups=afqdata.groups)\n",
    "    groups_pca = gpca.fit(harmonized_test.X).groups_out_\n",
    "\n",
    "    transformer = GroupPCA\n",
    "    transformer_kwargs = {\"groups\": afqdata.groups, \"n_components\": n_components}\n",
    "else:\n",
    "    transformer = False\n",
    "    transformer_kwargs = None\n",
    "\n",
    "pipe = make_afq_regressor_pipeline(\n",
    "    imputer_kwargs={\"strategy\": \"median\"},  # Use median imputation\n",
    "    use_cv_estimator=True,  # Automatically determine the best hyperparameters\n",
    "    scaler=\"standard\",  # Standard scale the features before regression\n",
    "    feature_transformer=transformer,  # See note above about group PCA\n",
    "    feature_transformer_kwargs=transformer_kwargs,\n",
    "    groups=(\n",
    "        groups_pca if do_group_pca else afqdata.groups\n",
    "    ),  # SGL will use the original feature groups or the PCA feature groups depending on the choice above # noqa E501\n",
    "    verbose=0,  # Be quiet!\n",
    "    pipeline_verbosity=False,  # No really, be quiet!\n",
    "    tuning_strategy=\"bayes\",  # Use BayesSearchCV to determine optimal hyperparameters\n",
    "    n_bayes_iter=20,  # Consider this many points in hyperparameter space\n",
    "    cv=3,  # Use three CV splits to evaluate each hyperparameter combination\n",
    "    l1_ratio=[0.0, 1.0],  # Explore the entire range of ``l1_ratio``\n",
    "    eps=5e-2,  # This is the ratio of the smallest to largest ``alpha`` value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(harmonized_train.X, harmonized_train.y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age = pipe.predict(harmonized_test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(harmonized_test.y[:, 0], pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipe.score(harmonized_test.X, harmonized_test.y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
